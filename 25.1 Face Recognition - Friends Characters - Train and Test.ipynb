{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Deep Learning Face Recogntion\n",
    "## Building a Friends TV Show Character Identifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The learning objective of this lesson (25.1) is the create a 'dumb' face classifer using our LittleVGG model. We are simply training it with 100s of pictures of each Friends Character, and testing our model using a Test Video. \n",
    "\n",
    "## You will see how this is an in-effective way to do Face Recognition, why?\n",
    "Because a traditional CNN will be looking at small subsections of a face to identify it. However, the angle and deformation of a face can easily throw off our model, making it mis-classify and match it to faces that aren't correct - this will happen a lot especially when our training data looks different to our test data. Imagine if the training data, one face was titled downward mostly. Our CNN will more likely identify any future face on our test data that looks downward, to be that face."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's train our model\n",
    "I've created a dataset with the faces of 4 Friends characters taken from a handful of different scenes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import cuda \n",
    "device = cuda.get_current_device()\n",
    "device.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2663 images belonging to 4 classes.\n",
      "Found 955 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "\n",
    "num_classes = 4\n",
    "img_rows, img_cols = 220, 220\n",
    "batch_size = 8\n",
    "\n",
    "train_data_dir = 'E:/25. Face Recognition/faces/train'\n",
    "validation_data_dir = 'E:/25. Face Recognition/faces/validation'\n",
    "\n",
    "# Let's use some data augmentaiton \n",
    "train_datagen = ImageDataGenerator(\n",
    "      rescale=1./255,\n",
    "      rotation_range=30,\n",
    "      shear_range=0.3,\n",
    "      zoom_range=0.3,\n",
    "      width_shift_range=0.4,\n",
    "      height_shift_range=0.4,\n",
    "      horizontal_flip=True,\n",
    "      fill_mode='nearest')\n",
    " \n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    " \n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_rows, img_cols),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        shuffle=True)\n",
    " \n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size=(img_rows, img_cols),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Our Keras imports\n",
    "from keras.models import Sequential\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.layers.advanced_activations import ELU\n",
    "from keras.layers.core import Activation, Flatten, Dropout, Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a simple VGG based model for Face Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_54 (Conv2D)           (None, 220, 220, 16)      448       \n",
      "_________________________________________________________________\n",
      "activation_63 (Activation)   (None, 220, 220, 16)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_60 (Batc (None, 220, 220, 16)      64        \n",
      "_________________________________________________________________\n",
      "conv2d_55 (Conv2D)           (None, 220, 220, 16)      2320      \n",
      "_________________________________________________________________\n",
      "activation_64 (Activation)   (None, 220, 220, 16)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_61 (Batc (None, 220, 220, 16)      64        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_27 (MaxPooling (None, 110, 110, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_56 (Conv2D)           (None, 110, 110, 32)      4640      \n",
      "_________________________________________________________________\n",
      "activation_65 (Activation)   (None, 110, 110, 32)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_62 (Batc (None, 110, 110, 32)      128       \n",
      "_________________________________________________________________\n",
      "conv2d_57 (Conv2D)           (None, 110, 110, 32)      9248      \n",
      "_________________________________________________________________\n",
      "activation_66 (Activation)   (None, 110, 110, 32)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_63 (Batc (None, 110, 110, 32)      128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_28 (MaxPooling (None, 55, 55, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 55, 55, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_58 (Conv2D)           (None, 55, 55, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_67 (Activation)   (None, 55, 55, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_64 (Batc (None, 55, 55, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_59 (Conv2D)           (None, 55, 55, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_68 (Activation)   (None, 55, 55, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_65 (Batc (None, 55, 55, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_29 (MaxPooling (None, 27, 27, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_60 (Conv2D)           (None, 27, 27, 128)       73856     \n",
      "_________________________________________________________________\n",
      "activation_69 (Activation)   (None, 27, 27, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_66 (Batc (None, 27, 27, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_61 (Conv2D)           (None, 27, 27, 128)       147584    \n",
      "_________________________________________________________________\n",
      "activation_70 (Activation)   (None, 27, 27, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_67 (Batc (None, 27, 27, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_30 (MaxPooling (None, 13, 13, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 13, 13, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_62 (Conv2D)           (None, 13, 13, 256)       295168    \n",
      "_________________________________________________________________\n",
      "activation_71 (Activation)   (None, 13, 13, 256)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_68 (Batc (None, 13, 13, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv2d_63 (Conv2D)           (None, 13, 13, 256)       590080    \n",
      "_________________________________________________________________\n",
      "activation_72 (Activation)   (None, 13, 13, 256)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_69 (Batc (None, 13, 13, 256)       1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_31 (MaxPooling (None, 6, 6, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_64 (Conv2D)           (None, 6, 6, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "activation_73 (Activation)   (None, 6, 6, 512)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_70 (Batc (None, 6, 6, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv2d_65 (Conv2D)           (None, 6, 6, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "activation_74 (Activation)   (None, 6, 6, 512)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_71 (Batc (None, 6, 6, 512)         2048      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_32 (MaxPooling (None, 3, 3, 512)         0         \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 3, 3, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_66 (Conv2D)           (None, 3, 3, 1024)        4719616   \n",
      "_________________________________________________________________\n",
      "activation_75 (Activation)   (None, 3, 3, 1024)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_72 (Batc (None, 3, 3, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv2d_67 (Conv2D)           (None, 3, 3, 1024)        9438208   \n",
      "_________________________________________________________________\n",
      "activation_76 (Activation)   (None, 3, 3, 1024)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_73 (Batc (None, 3, 3, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_33 (MaxPooling (None, 1, 1, 1024)        0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 64)                65600     \n",
      "_________________________________________________________________\n",
      "activation_77 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_74 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "activation_78 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_75 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 4)                 260       \n",
      "_________________________________________________________________\n",
      "activation_79 (Activation)   (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 18,963,348\n",
      "Trainable params: 18,954,964\n",
      "Non-trainable params: 8,384\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(16, (3, 3), padding = 'same', kernel_initializer=\"he_normal\",\n",
    "                 input_shape = (img_rows, img_cols, 3)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(16, (3, 3), padding = \"same\", kernel_initializer=\"he_normal\", \n",
    "                 input_shape = (img_rows, img_cols, 3)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "# Block #1: second CONV => RELU => CONV => RELU => POOL\n",
    "# layer set\n",
    "model.add(Conv2D(32, (3, 3), padding=\"same\", kernel_initializer=\"he_normal\"))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(32, (3, 3), padding=\"same\", kernel_initializer=\"he_normal\"))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Block #2: second CONV => RELU => CONV => RELU => POOL\n",
    "# layer set\n",
    "model.add(Conv2D(64, (3, 3), padding=\"same\", kernel_initializer=\"he_normal\"))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64, (3, 3), padding=\"same\", kernel_initializer=\"he_normal\"))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "\n",
    "# Block #3: third CONV => RELU => CONV => RELU => POOL\n",
    "# layer set\n",
    "model.add(Conv2D(128, (3, 3), padding=\"same\", kernel_initializer=\"he_normal\"))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(128, (3, 3), padding=\"same\", kernel_initializer=\"he_normal\"))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Block #4: third CONV => RELU => CONV => RELU => POOL\n",
    "# layer set\n",
    "model.add(Conv2D(256, (3, 3), padding=\"same\", kernel_initializer=\"he_normal\"))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(256, (3, 3), padding=\"same\", kernel_initializer=\"he_normal\"))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "\n",
    "# Block #vanish: third CONV => RELU => CONV => RELU => POOL\n",
    "# layer set\n",
    "model.add(Conv2D(512, (3, 3), padding=\"same\", kernel_initializer=\"he_normal\"))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(512, (3, 3), padding=\"same\", kernel_initializer=\"he_normal\"))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "\n",
    "# Block #vanish: third CONV => RELU => CONV => RELU => POOL\n",
    "# layer set\n",
    "model.add(Conv2D(1024, (3, 3), padding=\"same\", kernel_initializer=\"he_normal\"))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(1024, (3, 3), padding=\"same\", kernel_initializer=\"he_normal\"))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "# Block #5: first set of FC => RELU layers\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, kernel_initializer=\"he_normal\"))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Block #6: second set of FC => RELU layers\n",
    "model.add(Dense(64, kernel_initializer=\"he_normal\"))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Block #7: softmax classifier\n",
    "model.add(Dense(num_classes, kernel_initializer=\"he_normal\"))\n",
    "model.add(Activation(\"softmax\"))\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training our Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "  2/332 [..............................] - ETA: 12s - loss: 3.0462 - accuracy: 0.1875WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0279s vs `on_train_batch_end` time: 0.0499s). Check your callbacks.\n",
      "332/332 [==============================] - ETA: 0s - loss: 1.5833 - accuracy: 0.4580\n",
      "Epoch 00001: val_loss improved from inf to 1.70934, saving model to E:/25. Face Recognition\\face_recognition_friends_vgg.h5\n",
      "332/332 [==============================] - 39s 116ms/step - loss: 1.5833 - accuracy: 0.4580 - val_loss: 1.7093 - val_accuracy: 0.4611\n",
      "Epoch 2/70\n",
      "332/332 [==============================] - ETA: 0s - loss: 1.1045 - accuracy: 0.5902\n",
      "Epoch 00002: val_loss improved from 1.70934 to 1.53440, saving model to E:/25. Face Recognition\\face_recognition_friends_vgg.h5\n",
      "332/332 [==============================] - 38s 116ms/step - loss: 1.1045 - accuracy: 0.5902 - val_loss: 1.5344 - val_accuracy: 0.3718\n",
      "Epoch 3/70\n",
      "332/332 [==============================] - ETA: 0s - loss: 0.8424 - accuracy: 0.6863\n",
      "Epoch 00003: val_loss did not improve from 1.53440\n",
      "\n",
      "Epoch 00003: ReduceLROnPlateau reducing learning rate to 0.0004000000189989805.\n",
      "332/332 [==============================] - 35s 105ms/step - loss: 0.8424 - accuracy: 0.6863 - val_loss: 2.3885 - val_accuracy: 0.3950\n",
      "Epoch 4/70\n",
      "332/332 [==============================] - ETA: 0s - loss: 0.7024 - accuracy: 0.7420\n",
      "Epoch 00004: val_loss improved from 1.53440 to 0.49264, saving model to E:/25. Face Recognition\\face_recognition_friends_vgg.h5\n",
      "332/332 [==============================] - 39s 116ms/step - loss: 0.7024 - accuracy: 0.7420 - val_loss: 0.4926 - val_accuracy: 0.7920\n",
      "Epoch 5/70\n",
      "332/332 [==============================] - ETA: 0s - loss: 0.6522 - accuracy: 0.7499\n",
      "Epoch 00005: val_loss did not improve from 0.49264\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.00016000000759959222.\n",
      "332/332 [==============================] - 35s 105ms/step - loss: 0.6522 - accuracy: 0.7499 - val_loss: 0.9892 - val_accuracy: 0.5189\n",
      "Epoch 6/70\n",
      "332/332 [==============================] - ETA: 0s - loss: 0.5646 - accuracy: 0.8026\n",
      "Epoch 00006: val_loss improved from 0.49264 to 0.35929, saving model to E:/25. Face Recognition\\face_recognition_friends_vgg.h5\n",
      "332/332 [==============================] - 38s 115ms/step - loss: 0.5646 - accuracy: 0.8026 - val_loss: 0.3593 - val_accuracy: 0.8382\n",
      "Epoch 7/70\n",
      "332/332 [==============================] - ETA: 0s - loss: 0.5305 - accuracy: 0.8143\n",
      "Epoch 00007: val_loss improved from 0.35929 to 0.29625, saving model to E:/25. Face Recognition\\face_recognition_friends_vgg.h5\n",
      "332/332 [==============================] - 39s 117ms/step - loss: 0.5305 - accuracy: 0.8143 - val_loss: 0.2962 - val_accuracy: 0.8918\n",
      "Epoch 8/70\n",
      "332/332 [==============================] - ETA: 0s - loss: 0.5017 - accuracy: 0.8207\n",
      "Epoch 00008: val_loss improved from 0.29625 to 0.13623, saving model to E:/25. Face Recognition\\face_recognition_friends_vgg.h5\n",
      "332/332 [==============================] - 39s 117ms/step - loss: 0.5017 - accuracy: 0.8207 - val_loss: 0.1362 - val_accuracy: 0.9790\n",
      "Epoch 9/70\n",
      "332/332 [==============================] - ETA: 0s - loss: 0.5062 - accuracy: 0.8245\n",
      "Epoch 00009: val_loss improved from 0.13623 to 0.13362, saving model to E:/25. Face Recognition\\face_recognition_friends_vgg.h5\n",
      "332/332 [==============================] - 39s 116ms/step - loss: 0.5062 - accuracy: 0.8245 - val_loss: 0.1336 - val_accuracy: 0.9569\n",
      "Epoch 10/70\n",
      "332/332 [==============================] - ETA: 0s - loss: 0.4346 - accuracy: 0.8512\n",
      "Epoch 00010: val_loss did not improve from 0.13362\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 6.40000042039901e-05.\n",
      "332/332 [==============================] - 35s 106ms/step - loss: 0.4346 - accuracy: 0.8512 - val_loss: 0.1761 - val_accuracy: 0.9401\n",
      "Epoch 11/70\n",
      "332/332 [==============================] - ETA: 0s - loss: 0.3956 - accuracy: 0.8685\n",
      "Epoch 00011: val_loss improved from 0.13362 to 0.09375, saving model to E:/25. Face Recognition\\face_recognition_friends_vgg.h5\n",
      "332/332 [==============================] - 38s 114ms/step - loss: 0.3956 - accuracy: 0.8685 - val_loss: 0.0937 - val_accuracy: 0.9811\n",
      "Epoch 12/70\n",
      "332/332 [==============================] - ETA: 0s - loss: 0.4088 - accuracy: 0.8682\n",
      "Epoch 00012: val_loss improved from 0.09375 to 0.08164, saving model to E:/25. Face Recognition\\face_recognition_friends_vgg.h5\n",
      "332/332 [==============================] - 40s 120ms/step - loss: 0.4088 - accuracy: 0.8682 - val_loss: 0.0816 - val_accuracy: 0.9727\n",
      "Epoch 13/70\n",
      "332/332 [==============================] - ETA: 0s - loss: 0.3540 - accuracy: 0.8847\n",
      "Epoch 00013: val_loss improved from 0.08164 to 0.06651, saving model to E:/25. Face Recognition\\face_recognition_friends_vgg.h5\n",
      "332/332 [==============================] - 39s 117ms/step - loss: 0.3540 - accuracy: 0.8847 - val_loss: 0.0665 - val_accuracy: 0.9811\n",
      "Epoch 14/70\n",
      "332/332 [==============================] - ETA: 0s - loss: 0.3906 - accuracy: 0.8708\n",
      "Epoch 00014: val_loss improved from 0.06651 to 0.03765, saving model to E:/25. Face Recognition\\face_recognition_friends_vgg.h5\n",
      "332/332 [==============================] - 39s 116ms/step - loss: 0.3906 - accuracy: 0.8708 - val_loss: 0.0376 - val_accuracy: 0.9958\n",
      "Epoch 15/70\n",
      "332/332 [==============================] - ETA: 0s - loss: 0.4063 - accuracy: 0.8678 ETA: 1s - loss:\n",
      "Epoch 00015: val_loss did not improve from 0.03765\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 2.560000284574926e-05.\n",
      "332/332 [==============================] - 34s 102ms/step - loss: 0.4063 - accuracy: 0.8678 - val_loss: 0.0565 - val_accuracy: 0.9926\n",
      "Epoch 16/70\n",
      "332/332 [==============================] - ETA: 0s - loss: 0.3256 - accuracy: 0.8987\n",
      "Epoch 00016: val_loss did not improve from 0.03765\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 1.0240000847261399e-05.\n",
      "332/332 [==============================] - 40s 122ms/step - loss: 0.3256 - accuracy: 0.8987 - val_loss: 0.0681 - val_accuracy: 0.9853\n",
      "Epoch 17/70\n",
      "332/332 [==============================] - ETA: 0s - loss: 0.3198 - accuracy: 0.8998\n",
      "Epoch 00017: val_loss did not improve from 0.03765\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 4.09600033890456e-06.\n",
      "332/332 [==============================] - 43s 129ms/step - loss: 0.3198 - accuracy: 0.8998 - val_loss: 0.0546 - val_accuracy: 0.9937\n",
      "Epoch 18/70\n",
      "332/332 [==============================] - ETA: 0s - loss: 0.3147 - accuracy: 0.9013\n",
      "Epoch 00018: val_loss did not improve from 0.03765\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 1.6384001355618238e-06.\n",
      "332/332 [==============================] - 136s 410ms/step - loss: 0.3147 - accuracy: 0.9013 - val_loss: 0.0481 - val_accuracy: 0.9958\n",
      "Epoch 19/70\n",
      "332/332 [==============================] - ETA: 0s - loss: 0.3287 - accuracy: 0.8957\n",
      "Epoch 00019: val_loss did not improve from 0.03765\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 6.553600542247295e-07.\n",
      "332/332 [==============================] - 68s 205ms/step - loss: 0.3287 - accuracy: 0.8957 - val_loss: 0.0482 - val_accuracy: 0.9958\n",
      "Epoch 20/70\n",
      "332/332 [==============================] - ETA: 0s - loss: 0.2913 - accuracy: 0.9137\n",
      "Epoch 00020: val_loss did not improve from 0.03765\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 2.6214402168989184e-07.\n",
      "332/332 [==============================] - 68s 205ms/step - loss: 0.2913 - accuracy: 0.9137 - val_loss: 0.0484 - val_accuracy: 0.9958\n",
      "Epoch 21/70\n",
      "332/332 [==============================] - ETA: 0s - loss: 0.3178 - accuracy: 0.9013\n",
      "Epoch 00021: val_loss did not improve from 0.03765\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 1.0485761094969349e-07.\n",
      "332/332 [==============================] - 74s 222ms/step - loss: 0.3178 - accuracy: 0.9013 - val_loss: 0.0469 - val_accuracy: 0.9958\n",
      "Epoch 22/70\n",
      "332/332 [==============================] - ETA: 0s - loss: 0.3178 - accuracy: 0.9013\n",
      "Epoch 00022: val_loss did not improve from 0.03765\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 4.1943044948311586e-08.\n",
      "332/332 [==============================] - 130s 392ms/step - loss: 0.3178 - accuracy: 0.9013 - val_loss: 0.0485 - val_accuracy: 0.9947\n",
      "Epoch 23/70\n",
      "332/332 [==============================] - ETA: 0s - loss: 0.3062 - accuracy: 0.8979\n",
      "Epoch 00023: val_loss did not improve from 0.03765\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 1.677721854775882e-08.\n",
      "332/332 [==============================] - 434s 1s/step - loss: 0.3062 - accuracy: 0.8979 - val_loss: 0.0493 - val_accuracy: 0.9947\n",
      "Epoch 24/70\n",
      "332/332 [==============================] - ETA: 0s - loss: 0.3052 - accuracy: 0.9036\n",
      "Epoch 00024: val_loss did not improve from 0.03765\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 6.710887134886434e-09.\n",
      "332/332 [==============================] - 305s 920ms/step - loss: 0.3052 - accuracy: 0.9036 - val_loss: 0.0470 - val_accuracy: 0.9958\n",
      "Epoch 25/70\n",
      "332/332 [==============================] - ETA: 0s - loss: 0.3201 - accuracy: 0.8979\n",
      "Epoch 00025: val_loss did not improve from 0.03765\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 2.6843547829003003e-09.\n",
      "332/332 [==============================] - 318s 958ms/step - loss: 0.3201 - accuracy: 0.8979 - val_loss: 0.0482 - val_accuracy: 0.9958\n",
      "Epoch 26/70\n",
      "332/332 [==============================] - ETA: 0s - loss: 0.3063 - accuracy: 0.9141\n",
      "Epoch 00026: val_loss did not improve from 0.03765\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 1.0737418953965518e-09.\n",
      "332/332 [==============================] - 231s 697ms/step - loss: 0.3063 - accuracy: 0.9141 - val_loss: 0.0479 - val_accuracy: 0.9958\n",
      "Epoch 27/70\n",
      "332/332 [==============================] - ETA: 0s - loss: 0.3089 - accuracy: 0.9058\n",
      "Epoch 00027: val_loss did not improve from 0.03765\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 4.294967492768365e-10.\n",
      "332/332 [==============================] - 112s 337ms/step - loss: 0.3089 - accuracy: 0.9058 - val_loss: 0.0505 - val_accuracy: 0.9947\n",
      "Epoch 28/70\n",
      "332/332 [==============================] - ETA: 0s - loss: 0.3020 - accuracy: 0.9055"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import RMSprop, SGD, Adam\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "                     \n",
    "checkpoint = ModelCheckpoint(\"E:/25. Face Recognition/face_recognition_friends_vgg.h5\",\n",
    "                             monitor=\"val_loss\",\n",
    "                             mode=\"min\",\n",
    "                             save_best_only = True,\n",
    "                             verbose=1)\n",
    "\n",
    "earlystop = EarlyStopping(monitor = 'val_loss', \n",
    "                          min_delta = 0, \n",
    "                          patience = 15,\n",
    "                          verbose = 2,\n",
    "                          restore_best_weights = True)\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor = 'val_loss', factor = 0.4, patience = 1, verbose = 1, min_delta = 0.00000000000000000000000000001)\n",
    "\n",
    "# we put our call backs into a callback list\n",
    "callbacks = [checkpoint, reduce_lr]\n",
    "\n",
    "# We use a very small learning rate \n",
    "model.compile(loss = 'categorical_crossentropy',\n",
    "              optimizer = Adam(lr=0.001),\n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "nb_train_samples = 2663\n",
    "nb_validation_samples = 955\n",
    "epochs = 70\n",
    "\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch = nb_train_samples // batch_size,\n",
    "    epochs = epochs,\n",
    "    callbacks = callbacks,\n",
    "    validation_data = validation_generator,\n",
    "    validation_steps = nb_validation_samples // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Chandler': 0, 'Joey': 1, 'Pheobe': 2, 'Rachel': 3}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_generator.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('Chandler', 0), ('Joey', 1), ('Pheobe', 2), ('Rachel', 3)])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_generator.class_indices.items()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting our Class Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "from PIL import Image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "import random\n",
    "import cv2\n",
    "from keras.models import load_model\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('E:/25. Face Recognition/face_recognition_friends_vgg.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier('E:/25. Face Recognition/haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('E:/25. Face Recognition/testfriends.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def face_extractor(img):\n",
    "    # Function detects faces and returns the cropped face\n",
    "    # If no face detected, it returns the input image\n",
    "    \n",
    "    #gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(img, 1.3, 5)\n",
    "    \n",
    "    if faces is ():\n",
    "        return None\n",
    "    \n",
    "    # Crop all faces found\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,255),2)\n",
    "        cropped_face = img[y:y+h, x:x+w]\n",
    "\n",
    "    return cropped_face\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_classes = {0: 'Chandler', 1: 'Joey', 2: 'Pheobe', 3: 'Rachel'}\n",
    "\n",
    "def draw_label(image, point, label, font=cv2.FONT_HERSHEY_SIMPLEX,\n",
    "               font_scale=0.8, thickness=1):\n",
    "    size = cv2.getTextSize(label, font, font_scale, thickness)[0]\n",
    "    x, y = point\n",
    "    cv2.rectangle(image, (x, y - size[1]), (x + size[0], y), (255, 0, 0), cv2.FILLED)\n",
    "    cv2.putText(image, label, point, font, font_scale, (255, 255, 255), thickness, lineType=cv2.LINE_AA)\n",
    "    \n",
    "margin = 0.2\n",
    "# load model and weights\n",
    "img_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.39399692 0.6060031  0.         0.        ]]\n",
      "[[0.45889425 0.54110575 0.         0.        ]]\n",
      "[[0.4257712  0.57422876 0.         0.        ]]\n",
      "[[0.40944582 0.5905542  0.         0.        ]]\n",
      "[[0.41158932 0.5884106  0.         0.        ]]\n",
      "[[4.9645808e-01 5.0354189e-01 1.6220768e-38 0.0000000e+00]]\n",
      "[[0.2804793 0.7195207 0.        0.       ]]\n",
      "[[4.8221859e-01 5.1778138e-01 1.6996897e-38 0.0000000e+00]]\n",
      "[[0.58481216 0.41518778 0.         0.        ]]\n",
      "[[0.5799042 0.4200958 0.        0.       ]]\n",
      "[[5.9426618e-01 4.0573385e-01 3.5481471e-38 0.0000000e+00]]\n",
      "[[5.0072002e-01 4.9927998e-01 1.2990014e-38 0.0000000e+00]]\n",
      "[[4.6058649e-01 5.3941351e-01 1.5550261e-38 0.0000000e+00]]\n",
      "[[4.4924632e-01 5.5075365e-01 1.5810933e-38 0.0000000e+00]]\n",
      "[[4.4920006e-01 5.5079991e-01 1.5777074e-38 0.0000000e+00]]\n",
      "[[0.51954514 0.4804549  0.         0.        ]]\n",
      "[[5.9413278e-01 4.0586719e-01 1.7146802e-38 0.0000000e+00]]\n",
      "[[5.6800491e-01 4.3199503e-01 1.3807762e-38 0.0000000e+00]]\n",
      "[[0.5472599  0.45274007 0.         0.        ]]\n",
      "[[0.56564176 0.4343582  0.         0.        ]]\n",
      "[[6.2228185e-01 3.7771821e-01 1.4053055e-38 0.0000000e+00]]\n",
      "[[0.4708516 0.5291484 0.        0.       ]]\n",
      "[[5.0154305e-01 4.9845695e-01 1.3345655e-38 0.0000000e+00]]\n",
      "[[0.524428   0.47557202 0.         0.        ]]\n",
      "[[0.524428   0.47557202 0.         0.        ]]\n",
      "[[6.1581194e-01 3.8418806e-01 1.6935334e-38 0.0000000e+00]]\n",
      "[[6.7855000e-01 3.2145000e-01 3.0422442e-38 0.0000000e+00]]\n",
      "[[5.2777481e-01 4.7222522e-01 1.5943207e-38 0.0000000e+00]]\n",
      "[[1.0323829e-08 1.0000000e+00 0.0000000e+00 0.0000000e+00]]\n",
      "[[1.0394444e-08 1.0000000e+00 0.0000000e+00 0.0000000e+00]]\n",
      "[[9.321004e-09 1.000000e+00 0.000000e+00 0.000000e+00]]\n",
      "[[1.5618918e-08 1.0000000e+00 0.0000000e+00 0.0000000e+00]]\n",
      "[[3.7632257e-09 1.0000000e+00 0.0000000e+00 0.0000000e+00]]\n",
      "[[2.469208e-09 1.000000e+00 0.000000e+00 0.000000e+00]]\n",
      "[[3.8846686e-09 1.0000000e+00 0.0000000e+00 0.0000000e+00]]\n",
      "[[9.497048e-10 1.000000e+00 0.000000e+00 0.000000e+00]]\n",
      "[[2.7179945e-09 1.0000000e+00 0.0000000e+00 0.0000000e+00]]\n",
      "[[0.02233611 0.9776638  0.         0.        ]]\n",
      "[[0.0166128  0.98338723 0.         0.        ]]\n",
      "[[0.01643581 0.98356426 0.         0.        ]]\n",
      "[[0.003446 0.996554 0.       0.      ]]\n",
      "[[0.05814496 0.941855   0.         0.        ]]\n",
      "[[0.03887931 0.9611207  0.         0.        ]]\n",
      "[[0.02937601 0.97062397 0.         0.        ]]\n",
      "[[0.02769262 0.9723074  0.         0.        ]]\n",
      "[[0.02114737 0.97885257 0.         0.        ]]\n",
      "[[0.0101168  0.98988324 0.         0.        ]]\n",
      "[[0.02036208 0.9796379  0.         0.        ]]\n",
      "[[0.13424079 0.86575925 0.         0.        ]]\n",
      "[[0.14130919 0.8586908  0.         0.        ]]\n",
      "[[1.1511403e-01 8.8488591e-01 2.6059182e-38 0.0000000e+00]]\n",
      "[[0.03877695 0.96122307 0.         0.        ]]\n",
      "[[0.04042383 0.95957613 0.         0.        ]]\n",
      "[[0.02930453 0.9706955  0.         0.        ]]\n",
      "[[0.02873123 0.9712687  0.         0.        ]]\n",
      "[[0.07356799 0.92643195 0.         0.        ]]\n",
      "[[0.06855843 0.93144155 0.         0.        ]]\n",
      "[[0.00756514 0.99243486 0.         0.        ]]\n",
      "[[0.01653461 0.98346543 0.         0.        ]]\n",
      "[[0.01895656 0.9810434  0.         0.        ]]\n",
      "[[1.3445507e-01 8.6554492e-01 2.1080579e-38 0.0000000e+00]]\n",
      "[[1.1301930e-01 8.8698077e-01 1.5183024e-38 0.0000000e+00]]\n",
      "[[0.04775595 0.95224404 0.         0.        ]]\n",
      "[[0.0366831 0.9633169 0.        0.       ]]\n",
      "[[0.04008428 0.95991576 0.         0.        ]]\n",
      "[[0.05943206 0.940568   0.         0.        ]]\n",
      "[[0.02827009 0.9717299  0.         0.        ]]\n",
      "[[0.00218952 0.99781054 0.         0.        ]]\n",
      "[[0.00368742 0.99631256 0.         0.        ]]\n",
      "[[0.00372993 0.99627006 0.         0.        ]]\n",
      "[[0.01714499 0.9828551  0.         0.        ]]\n",
      "[[2.5842545e-04 9.9974161e-01 0.0000000e+00 0.0000000e+00]]\n",
      "[[0.00228191 0.9977181  0.         0.        ]]\n",
      "[[0.0012212  0.99877876 0.         0.        ]]\n",
      "[[5.083210e-04 9.994917e-01 0.000000e+00 0.000000e+00]]\n",
      "[[0.00100593 0.99899405 0.         0.        ]]\n",
      "[[7.151220e-04 9.992849e-01 0.000000e+00 0.000000e+00]]\n",
      "[[3.6463747e-03 9.9635363e-01 3.0812429e-38 0.0000000e+00]]\n",
      "[[4.2414279e-03 9.9575859e-01 1.3284422e-38 0.0000000e+00]]\n",
      "[[4.2246575e-03 9.9577540e-01 1.2568441e-38 0.0000000e+00]]\n",
      "[[1.8079604e-01 8.1920391e-01 3.3241456e-37 0.0000000e+00]]\n",
      "[[1.3366482e-01 8.6633515e-01 1.4531429e-37 0.0000000e+00]]\n",
      "[[8.8688098e-02 9.1131192e-01 1.7038546e-37 0.0000000e+00]]\n",
      "[[4.1096177e-02 9.5890385e-01 4.5814666e-38 0.0000000e+00]]\n",
      "[[1.3364098e-02 9.8663586e-01 1.6952658e-38 0.0000000e+00]]\n",
      "[[1.4674254e-01 8.5325748e-01 3.2484141e-37 0.0000000e+00]]\n",
      "[[3.9031405e-02 9.6096855e-01 7.6342040e-38 0.0000000e+00]]\n",
      "[[2.892564e-01 7.107436e-01 5.266732e-37 0.000000e+00]]\n",
      "[[1.0323331e-01 8.9676672e-01 1.8999336e-37 0.0000000e+00]]\n",
      "[[1.6532947e-01 8.3467048e-01 3.5802070e-37 0.0000000e+00]]\n",
      "[[1.468835e-01 8.531166e-01 2.310288e-37 0.000000e+00]]\n",
      "[[1.6893834e-02 9.8310620e-01 5.1926365e-38 0.0000000e+00]]\n",
      "[[1.9106996e-03 9.9808925e-01 3.3308077e-38 0.0000000e+00]]\n",
      "[[1.3973102e-03 9.9860269e-01 2.1024363e-38 0.0000000e+00]]\n",
      "[[1.4480324e-03 9.9855191e-01 2.0726275e-38 0.0000000e+00]]\n",
      "[[4.568240e-03 9.954318e-01 6.446242e-38 0.000000e+00]]\n",
      "[[6.3231395e-04 9.9936765e-01 0.0000000e+00 0.0000000e+00]]\n",
      "[[3.854300e-04 9.996146e-01 0.000000e+00 0.000000e+00]]\n",
      "[[5.0854392e-04 9.9949145e-01 0.0000000e+00 0.0000000e+00]]\n",
      "[[9.6583873e-04 9.9903417e-01 0.0000000e+00 0.0000000e+00]]\n",
      "[[5.9674638e-03 9.9403256e-01 4.5034871e-38 0.0000000e+00]]\n",
      "[[0.0015306 0.9984694 0.        0.       ]]\n",
      "[[1.8692412e-03 9.9813074e-01 5.1219695e-38 0.0000000e+00]]\n",
      "[[6.0186401e-04 9.9939811e-01 1.9853953e-38 0.0000000e+00]]\n",
      "[[4.5965079e-04 9.9954033e-01 1.5852719e-38 0.0000000e+00]]\n",
      "[[2.4504683e-04 9.9975497e-01 0.0000000e+00 0.0000000e+00]]\n",
      "[[0.1386216  0.86137843 0.         0.        ]]\n",
      "[[0.08290332 0.9170967  0.         0.        ]]\n",
      "[[2.8585532e-01 7.1414471e-01 1.5801865e-37 0.0000000e+00]]\n",
      "[[2.8688982e-01 7.1311015e-01 1.5872427e-37 0.0000000e+00]]\n",
      "[[0.1539055 0.8460945 0.        0.       ]]\n",
      "[[0.13784815 0.86215186 0.         0.        ]]\n",
      "[[0.08787827 0.9121217  0.         0.        ]]\n",
      "[[0.13768728 0.8623127  0.         0.        ]]\n",
      "[[0.13559966 0.8644004  0.         0.        ]]\n",
      "[[2.8127217e-01 7.1872783e-01 1.4810532e-38 0.0000000e+00]]\n",
      "[[0.14449604 0.8555039  0.         0.        ]]\n",
      "[[4.9467486e-01 5.0532508e-01 4.4450768e-38 0.0000000e+00]]\n",
      "[[5.7025748e-01 4.2974252e-01 2.8941836e-38 0.0000000e+00]]\n",
      "[[5.6645703e-01 4.3354300e-01 3.0002254e-38 0.0000000e+00]]\n",
      "[[7.0112908e-01 2.9887092e-01 4.1294696e-38 0.0000000e+00]]\n",
      "[[8.1243587e-01 1.8756421e-01 4.7025211e-38 0.0000000e+00]]\n",
      "[[0.38371795 0.61628205 0.         0.        ]]\n",
      "[[5.5209643e-01 4.4790363e-01 1.7611634e-38 0.0000000e+00]]\n",
      "[[5.4505396e-01 4.5494601e-01 1.8038820e-38 0.0000000e+00]]\n",
      "[[7.6275975e-01 2.3724030e-01 7.3001053e-38 0.0000000e+00]]\n",
      "[[6.6742295e-01 3.3257705e-01 4.6811706e-38 0.0000000e+00]]\n",
      "[[7.5036269e-01 2.4963726e-01 5.2973364e-38 0.0000000e+00]]\n",
      "[[0.455595 0.544405 0.       0.      ]]\n",
      "[[0.45463008 0.54536986 0.         0.        ]]\n",
      "[[0.20501193 0.7949881  0.         0.        ]]\n",
      "[[0.13422261 0.8657774  0.         0.        ]]\n",
      "[[0.06535833 0.93464166 0.         0.        ]]\n",
      "[[0.04946494 0.95053506 0.         0.        ]]\n",
      "[[0.05231023 0.9476898  0.         0.        ]]\n",
      "[[0.1126634 0.8873366 0.        0.       ]]\n",
      "[[0.13576517 0.8642348  0.         0.        ]]\n",
      "[[0.10693589 0.8930641  0.         0.        ]]\n",
      "[[0.19735743 0.8026426  0.         0.        ]]\n",
      "[[0.19744687 0.8025531  0.         0.        ]]\n",
      "[[0.06253356 0.93746644 0.         0.        ]]\n",
      "[[0.06059928 0.93940073 0.         0.        ]]\n",
      "[[0.06115782 0.93884224 0.         0.        ]]\n",
      "[[0.06700357 0.9329964  0.         0.        ]]\n",
      "[[0.06615746 0.9338426  0.         0.        ]]\n",
      "[[0.09331299 0.90668696 0.         0.        ]]\n",
      "[[0.06985934 0.9301406  0.         0.        ]]\n",
      "[[0.07645184 0.9235481  0.         0.        ]]\n",
      "[[0.05087529 0.9491247  0.         0.        ]]\n",
      "[[0.08686174 0.9131383  0.         0.        ]]\n",
      "[[2.4018653e-01 7.5981343e-01 4.2646403e-38 0.0000000e+00]]\n",
      "[[2.5565639e-01 7.4434358e-01 5.9019166e-38 0.0000000e+00]]\n",
      "[[0.17918132 0.8208187  0.         0.        ]]\n",
      "[[0.23446347 0.7655365  0.         0.        ]]\n",
      "[[0.23106205 0.76893795 0.         0.        ]]\n",
      "[[0.19385342 0.80614656 0.         0.        ]]\n",
      "[[0.36607614 0.6339239  0.         0.        ]]\n",
      "[[0.3982775 0.6017225 0.        0.       ]]\n",
      "[[0.3898931 0.6101069 0.        0.       ]]\n",
      "[[0.21843027 0.7815697  0.         0.        ]]\n",
      "[[0.35554323 0.6444568  0.         0.        ]]\n",
      "[[0.29757756 0.70242244 0.         0.        ]]\n",
      "[[3.8654178e-01 6.1345822e-01 8.0754555e-38 0.0000000e+00]]\n",
      "[[3.8723493e-01 6.1276507e-01 7.9644525e-38 0.0000000e+00]]\n",
      "[[4.8038441e-01 5.1961559e-01 4.4756784e-38 0.0000000e+00]]\n",
      "[[0.4806396  0.51936036 0.         0.        ]]\n",
      "[[0.694586   0.30541402 0.         0.        ]]\n",
      "[[0.58623326 0.41376674 0.         0.        ]]\n",
      "[[0.5784286  0.42157134 0.         0.        ]]\n",
      "[[0.21202865 0.7879714  0.         0.        ]]\n",
      "[[0.31631976 0.68368024 0.         0.        ]]\n",
      "[[0.19436422 0.80563575 0.         0.        ]]\n",
      "[[0.3966897 0.6033102 0.        0.       ]]\n",
      "[[0.39372185 0.6062781  0.         0.        ]]\n",
      "[[0.5279174 0.4720826 0.        0.       ]]\n",
      "[[0.22406672 0.7759332  0.         0.        ]]\n",
      "[[0.37572974 0.62427026 0.         0.        ]]\n",
      "[[0.44936433 0.5506357  0.         0.        ]]\n",
      "[[0.43472934 0.5652706  0.         0.        ]]\n",
      "[[0.569444   0.43055597 0.         0.        ]]\n",
      "[[0.16638738 0.8336126  0.         0.        ]]\n",
      "[[0.26478592 0.7352141  0.         0.        ]]\n",
      "[[0.16439591 0.83560413 0.         0.        ]]\n",
      "[[0.17000252 0.8299975  0.         0.        ]]\n",
      "[[0.03158176 0.9684182  0.         0.        ]]\n",
      "[[0.08622093 0.9137791  0.         0.        ]]\n",
      "[[4.1924202e-01 5.8075798e-01 1.2068444e-37 0.0000000e+00]]\n",
      "[[0.01993158 0.9800685  0.         0.        ]]\n",
      "[[0.01935097 0.980649   0.         0.        ]]\n",
      "[[0.03757372 0.9624263  0.         0.        ]]\n",
      "[[0.04794399 0.952056   0.         0.        ]]\n",
      "[[3.7750390e-01 6.2249607e-01 1.7248362e-37 0.0000000e+00]]\n",
      "[[1.8426926e-01 8.1573075e-01 4.9348026e-38 0.0000000e+00]]\n",
      "[[1.8299685e-01 8.1700313e-01 5.0555794e-38 0.0000000e+00]]\n",
      "[[1.6571702e-01 8.3428299e-01 4.8366455e-38 0.0000000e+00]]\n",
      "[[2.1880886e-01 7.8119111e-01 4.4302236e-38 0.0000000e+00]]\n",
      "[[1.6923554e-01 8.3076447e-01 1.7850975e-36 0.0000000e+00]]\n",
      "[[1.6820319e-01 8.3179677e-01 1.8208853e-36 0.0000000e+00]]\n",
      "[[1.2728563e-01 8.7271434e-01 4.3511313e-37 0.0000000e+00]]\n",
      "[[4.3134933e-05 9.9995685e-01 0.0000000e+00 0.0000000e+00]]\n",
      "[[9.4997793e-02 9.0500218e-01 8.3828854e-36 0.0000000e+00]]\n",
      "[[1.0612863e-02 9.8938715e-01 2.6292583e-37 0.0000000e+00]]\n",
      "[[2.7148146e-03 9.9728513e-01 1.9420776e-38 0.0000000e+00]]\n",
      "[[2.7249034e-03 9.9727505e-01 1.9850966e-38 0.0000000e+00]]\n",
      "[[9.5529540e-05 9.9990451e-01 3.4378548e-38 0.0000000e+00]]\n",
      "[[4.9675896e-04 9.9950325e-01 7.7376007e-38 0.0000000e+00]]\n",
      "[[4.9100805e-04 9.9950898e-01 8.0913081e-38 0.0000000e+00]]\n",
      "[[5.8159197e-04 9.9941838e-01 3.2782783e-38 0.0000000e+00]]\n",
      "[[7.287772e-04 9.992712e-01 0.000000e+00 0.000000e+00]]\n",
      "[[2.3848373e-04 9.9976152e-01 0.0000000e+00 0.0000000e+00]]\n",
      "[[5.572474e-05 9.999443e-01 0.000000e+00 0.000000e+00]]\n",
      "[[5.3989144e-05 9.9994600e-01 0.0000000e+00 0.0000000e+00]]\n",
      "[[6.690229e-04 9.993310e-01 0.000000e+00 0.000000e+00]]\n",
      "[[1.5075646e-04 9.9984920e-01 0.0000000e+00 0.0000000e+00]]\n",
      "[[0.00314884 0.99685115 0.         0.        ]]\n",
      "[[5.590230e-05 9.999441e-01 0.000000e+00 0.000000e+00]]\n",
      "[[5.9154423e-05 9.9994087e-01 0.0000000e+00 0.0000000e+00]]\n",
      "[[7.4697775e-05 9.9992526e-01 0.0000000e+00 0.0000000e+00]]\n",
      "[[2.8836046e-05 9.9997115e-01 0.0000000e+00 0.0000000e+00]]\n",
      "[[2.4307404e-04 9.9975687e-01 0.0000000e+00 0.0000000e+00]]\n",
      "[[2.6013312e-04 9.9973983e-01 0.0000000e+00 0.0000000e+00]]\n",
      "[[2.5893794e-04 9.9974102e-01 0.0000000e+00 0.0000000e+00]]\n",
      "[[9.686789e-04 9.990313e-01 0.000000e+00 0.000000e+00]]\n",
      "[[4.6132761e-04 9.9953866e-01 0.0000000e+00 0.0000000e+00]]\n",
      "[[0.0012835 0.9987165 0.        0.       ]]\n",
      "[[0.01285893 0.987141   0.         0.        ]]\n",
      "[[0.01317532 0.9868247  0.         0.        ]]\n",
      "[[0.01145714 0.9885429  0.         0.        ]]\n",
      "[[0.05466483 0.94533515 0.         0.        ]]\n",
      "[[0.00311534 0.99688464 0.         0.        ]]\n",
      "[[0.02398836 0.97601163 0.         0.        ]]\n",
      "[[0.02570423 0.9742958  0.         0.        ]]\n",
      "[[0.00766702 0.99233294 0.         0.        ]]\n",
      "[[2.4395881e-02 9.7560412e-01 2.2595981e-38 0.0000000e+00]]\n",
      "[[1.4347646e-01 8.5652351e-01 4.6747640e-37 0.0000000e+00]]\n",
      "[[1.3360627e-02 9.8663932e-01 2.3440108e-38 0.0000000e+00]]\n",
      "[[1.4220360e-02 9.8577964e-01 2.5643896e-38 0.0000000e+00]]\n",
      "[[1.2079831e-01 8.7920165e-01 2.6644301e-36 0.0000000e+00]]\n",
      "[[2.2838235e-02 9.7716171e-01 4.5481637e-37 0.0000000e+00]]\n",
      "[[6.7315213e-03 9.9326843e-01 5.1237649e-38 0.0000000e+00]]\n",
      "[[2.7655733e-01 7.2344267e-01 1.3774395e-35 0.0000000e+00]]\n",
      "[[2.6548156e-01 7.3451841e-01 1.4051160e-35 0.0000000e+00]]\n",
      "[[3.5188859e-03 9.9648106e-01 4.4301174e-37 0.0000000e+00]]\n",
      "[[1.2268032e-03 9.9877316e-01 5.0257889e-38 0.0000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    face=face_extractor(frame)\n",
    "    if type(face) is np.ndarray:\n",
    "        face = cv2.resize(face, (224, 224))\n",
    "        im = Image.fromarray(face, 'RGB')\n",
    "           #Resizing into 128x128 because we trained the model with this image size.\n",
    "        img_array = np.array(im)\n",
    "                    #Our keras model used a 4D tensor, (images x height x width x channel)\n",
    "                    #So changing dimension 128x128x3 into 1x128x128x3 \n",
    "        img_array = np.expand_dims(img_array, axis=0)\n",
    "        pred = model.predict(img_array)\n",
    "        print(pred)\n",
    "       \n",
    "                     \n",
    "        name=\"None matching\"\n",
    "\n",
    "        if(pred[0][0]>0.5):\n",
    "            name='Chandler'\n",
    "            cv2.putText(img_array,name, (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
    "        elif(pred[0][1]>0.5):\n",
    "            name='Joey'\n",
    "            cv2.putText(img_array,name, (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
    "        elif(pred[0][2]>0.5):\n",
    "            name='Pheobe'\n",
    "            cv2.putText(img_array,name, (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
    "        elif(pred[0][3]>0.5):\n",
    "            name='Rachel'\n",
    "            cv2.putText(img_array,name, (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
    "            \n",
    "    else:\n",
    "        cv2.putText(frame,\"No face found\", (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
    "    cv2.imshow('Video', frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing our model on some real video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
